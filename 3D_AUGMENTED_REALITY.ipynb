{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyLYYtMlVlTX"
      },
      "source": [
        "#3D Augmented Reality Final Project (A.Y. 2022/2023)\n",
        "\n",
        "\n",
        "Project 6: Local Features Compression Using Autoencoders\n",
        "---\n",
        "**University of Padua**<br>\n",
        "*Master Degree in ICT for Internet and Multimedia - Cybersystems*\n",
        "<br>\n",
        "<br>\n",
        "**Students:** \n",
        "<br>\n",
        "\n",
        "\n",
        "*   *Gianpietro Nicoletti 2053042*\n",
        "*   *Ege Alp Turkyener 2049576*\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulted data can be found here(i.e. the datasets + the list of keypoints and the matches with all the possible versions: original, compressed, reconstructed):\n",
        "\n",
        "[RESULTS](https://drive.google.com/drive/folders/1wd_uG5kRr639V9tIZgj11OiLidcqUAb8?usp=sharing)\n",
        "\n",
        "A short report about this project can be found here: <br>[REPORT](https://drive.google.com/file/d/1Gi7JMtolp5CzvNOMU6bjaM2G6Xwokog7/view?usp=sharing)"
      ],
      "metadata": {
        "id": "HWhKUQ19K160"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import of the libraries"
      ],
      "metadata": {
        "id": "Zj3KCrMvJVh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn-fjyXn1IZ3",
        "outputId": "dc3d1cff-a9f1-4b3a-d893-4ac1710b4d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycolmap\n",
            "  Downloading pycolmap-0.3.0-cp38-cp38-manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycolmap\n",
            "Successfully installed pycolmap-0.3.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "!pip install pycolmap\n",
        "import pycolmap\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Conv2DTranspose, Flatten, Reshape, LeakyReLU, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras import losses\n",
        "from keras.utils import Sequence, plot_model\n",
        "\n",
        "from tqdm import trange\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PURPLE = '\\033[95m'\n",
        "CYAN = '\\033[96m'\n",
        "DARKCYAN = '\\033[36m'\n",
        "BLUE = '\\033[94m'\n",
        "GREEN = '\\033[92m'\n",
        "YELLOW = '\\033[93m'\n",
        "RED = '\\033[91m'\n",
        "BOLD = '\\033[1m'\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'"
      ],
      "metadata": {
        "id": "n3RD2PgUOWIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading of the datasets"
      ],
      "metadata": {
        "id": "JVh3QsETJZ2O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "sldwV6cSMU_G",
        "outputId": "2cdb4277-e334-44f4-f795-7a65daa71375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.6.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1_6Jd7BqD7VLhXHGF4ez4AbGHJm-lmRIN&export=download\n",
            "To: /content/castle-P30.zip\n",
            "100%|██████████| 81.2M/81.2M [00:02<00:00, 31.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1c1dFm0Ci_zMiIJrb9WfZ4xOfNA3IG0D_&export=download\n",
            "To: /content/castle-P19.zip\n",
            "100%|██████████| 51.4M/51.4M [00:01<00:00, 36.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=19L9VELLy0s2q8wsevkWq1n0VCfXAyQ1h&export=download\n",
            "To: /content/fountain-P11.zip\n",
            "100%|██████████| 32.9M/32.9M [00:03<00:00, 8.24MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fountain-P11.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#downloading the datasets\n",
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!pip install --upgrade gdown\n",
        "import gdown\n",
        "\n",
        "#train set\n",
        "url = \"https://drive.google.com/u/0/uc?id=1_6Jd7BqD7VLhXHGF4ez4AbGHJm-lmRIN&export=download\"\n",
        "output = \"castle-P30.zip\"\n",
        "gdown.download(url, output)\n",
        "\n",
        "url = \"https://drive.google.com/u/0/uc?id=1c1dFm0Ci_zMiIJrb9WfZ4xOfNA3IG0D_&export=download\"\n",
        "output = \"castle-P19.zip\"\n",
        "gdown.download(url, output)\n",
        "\n",
        "#test set\n",
        "url = \"https://drive.google.com/u/0/uc?id=19L9VELLy0s2q8wsevkWq1n0VCfXAyQ1h&export=download\"\n",
        "output = \"fountain-P11.zip\"\n",
        "gdown.download(url, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7K-GA8hyDIP",
        "outputId": "4f0dd6ef-6801-43fc-e318-ba76122f0396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  castle-P30.zip\n",
            "   creating: castle-P30/gt_dense_cameras/\n",
            "  inflating: castle-P30/gt_dense_cameras/0000.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0001.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0002.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0003.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0004.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0005.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0006.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0007.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0008.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0009.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0010.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0011.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0012.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0013.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0014.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0015.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0016.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0017.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0018.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0019.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0020.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0021.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0022.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0023.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0024.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0025.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0026.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0027.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0028.jpg.camera  \n",
            "  inflating: castle-P30/gt_dense_cameras/0029.jpg.camera  \n",
            "   creating: castle-P30/images/\n",
            "  inflating: castle-P30/images/0000.jpg  \n",
            "  inflating: castle-P30/images/0001.jpg  \n",
            "  inflating: castle-P30/images/0002.jpg  \n",
            "  inflating: castle-P30/images/0003.jpg  \n",
            "  inflating: castle-P30/images/0004.jpg  \n",
            "  inflating: castle-P30/images/0005.jpg  \n",
            "  inflating: castle-P30/images/0006.jpg  \n",
            "  inflating: castle-P30/images/0007.jpg  \n",
            "  inflating: castle-P30/images/0008.jpg  \n",
            "  inflating: castle-P30/images/0009.jpg  \n",
            "  inflating: castle-P30/images/0010.jpg  \n",
            "  inflating: castle-P30/images/0011.jpg  \n",
            "  inflating: castle-P30/images/0012.jpg  \n",
            "  inflating: castle-P30/images/0013.jpg  \n",
            "  inflating: castle-P30/images/0014.jpg  \n",
            "  inflating: castle-P30/images/0015.jpg  \n",
            "  inflating: castle-P30/images/0016.jpg  \n",
            "  inflating: castle-P30/images/0017.jpg  \n",
            "  inflating: castle-P30/images/0018.jpg  \n",
            "  inflating: castle-P30/images/0019.jpg  \n",
            "  inflating: castle-P30/images/0020.jpg  \n",
            "  inflating: castle-P30/images/0021.jpg  \n",
            "  inflating: castle-P30/images/0022.jpg  \n",
            "  inflating: castle-P30/images/0023.jpg  \n",
            "  inflating: castle-P30/images/0024.jpg  \n",
            "  inflating: castle-P30/images/0025.jpg  \n",
            "  inflating: castle-P30/images/0026.jpg  \n",
            "  inflating: castle-P30/images/0027.jpg  \n",
            "  inflating: castle-P30/images/0028.jpg  \n",
            "  inflating: castle-P30/images/0029.jpg  \n",
            "  inflating: castle-P30/images/K.txt  \n",
            "Archive:  castle-P19.zip\n",
            "   creating: castle-P19/gt_dense_cameras/\n",
            "  inflating: castle-P19/gt_dense_cameras/0000.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0001.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0002.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0003.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0004.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0005.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0006.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0007.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0008.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0009.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0010.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0011.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0012.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0013.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0014.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0015.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0016.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0017.jpg.camera  \n",
            "  inflating: castle-P19/gt_dense_cameras/0018.jpg.camera  \n",
            "   creating: castle-P19/images/\n",
            "  inflating: castle-P19/images/0000.jpg  \n",
            "  inflating: castle-P19/images/0001.jpg  \n",
            "  inflating: castle-P19/images/0002.jpg  \n",
            "  inflating: castle-P19/images/0003.jpg  \n",
            "  inflating: castle-P19/images/0004.jpg  \n",
            "  inflating: castle-P19/images/0005.jpg  \n",
            "  inflating: castle-P19/images/0006.jpg  \n",
            "  inflating: castle-P19/images/0007.jpg  \n",
            "  inflating: castle-P19/images/0008.jpg  \n",
            "  inflating: castle-P19/images/0009.jpg  \n",
            "  inflating: castle-P19/images/0010.jpg  \n",
            "  inflating: castle-P19/images/0011.jpg  \n",
            "  inflating: castle-P19/images/0012.jpg  \n",
            "  inflating: castle-P19/images/0013.jpg  \n",
            "  inflating: castle-P19/images/0014.jpg  \n",
            "  inflating: castle-P19/images/0015.jpg  \n",
            "  inflating: castle-P19/images/0016.jpg  \n",
            "  inflating: castle-P19/images/0017.jpg  \n",
            "  inflating: castle-P19/images/0018.jpg  \n",
            "  inflating: castle-P19/images/K.txt  \n",
            "Archive:  fountain-P11.zip\n",
            "   creating: fountain-P11/gt_dense_cameras/\n",
            "  inflating: fountain-P11/gt_dense_cameras/0000.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0001.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0002.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0003.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0004.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0005.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0006.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0007.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0008.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0009.jpg.camera  \n",
            "  inflating: fountain-P11/gt_dense_cameras/0010.jpg.camera  \n",
            "   creating: fountain-P11/images/\n",
            "  inflating: fountain-P11/images/0000.jpg  \n",
            "  inflating: fountain-P11/images/0001.jpg  \n",
            "  inflating: fountain-P11/images/0002.jpg  \n",
            "  inflating: fountain-P11/images/0003.jpg  \n",
            "  inflating: fountain-P11/images/0004.jpg  \n",
            "  inflating: fountain-P11/images/0005.jpg  \n",
            "  inflating: fountain-P11/images/0006.jpg  \n",
            "  inflating: fountain-P11/images/0007.jpg  \n",
            "  inflating: fountain-P11/images/0008.jpg  \n",
            "  inflating: fountain-P11/images/0009.jpg  \n",
            "  inflating: fountain-P11/images/0010.jpg  \n",
            "  inflating: fountain-P11/images/K.txt  \n"
          ]
        }
      ],
      "source": [
        "#unzipping the folders and remove useless files\n",
        "\n",
        "#train set\n",
        "!unzip castle-P30.zip\n",
        "!rm /content/castle-P30/images/K.txt\n",
        "!unzip castle-P19.zip\n",
        "!rm /content/castle-P19/images/K.txt\n",
        "\n",
        "#test set\n",
        "!unzip fountain-P11.zip\n",
        "!rm /content/fountain-P11/images/K.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the utility functions"
      ],
      "metadata": {
        "id": "GRs_cCidJmg7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R580wIU_zzxP"
      },
      "outputs": [],
      "source": [
        "def compute_dataset(folders,filename = None):\n",
        "\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "    folders : list or array like\n",
        "        List of folders where the images are\n",
        "\n",
        "    filename : str, optional\n",
        "        A specific file inside the folder\n",
        "  \n",
        "  Returns\n",
        "  ----------\n",
        "    dataset: list\n",
        "        All the keypoint,scores and descriptors for the given images inside the folders (or the specified image)\n",
        "  \n",
        "  \"\"\"\n",
        "  #ERROR\n",
        "  if(len(folders) != 1 and filename is not None):\n",
        "\n",
        "    print(\"You can select only a specific image in a specific folder!\")\n",
        "    return None\n",
        "\n",
        "\n",
        "  dataset = []\n",
        "\n",
        "  #compute for all the images inside the folder\n",
        "  if(filename is None):\n",
        "\n",
        "    for folder in folders:\n",
        "      # Get a list of files in the folder\n",
        "      files = os.listdir(folder)\n",
        "\n",
        "      \n",
        "      # Iterate over the files\n",
        "      for i in trange(len(files)):\n",
        "          \n",
        "          file = files[i]\n",
        "          # Construct the full path to the file\n",
        "          file_path = os.path.join(folder, file)\n",
        "\n",
        "          #checking if the path is a file or a directory\n",
        "          if os.path.isdir(file_path):\n",
        "            continue\n",
        "\n",
        "          img = Image.open(file_path).convert('RGB')\n",
        "          img = ImageOps.grayscale(img)\n",
        "          img = np.array(img).astype(np.float) / 255\n",
        "\n",
        "          sift = pycolmap.Sift()\n",
        "\n",
        "          keypoints, scores, descriptors = sift.extract(img)\n",
        "\n",
        "          dataset.append([keypoints, scores, descriptors])\n",
        "      \n",
        "  #compute for a specific image\n",
        "  else:\n",
        "\n",
        "    for i in trange(len(folders)):\n",
        "      file_path = os.path.join(folders[0], filename)\n",
        "\n",
        "      img = Image.open(file_path).convert('RGB')\n",
        "      img = ImageOps.grayscale(img)\n",
        "      img = np.array(img).astype(np.float64) / 255\n",
        "\n",
        "      sift = pycolmap.Sift()\n",
        "\n",
        "      keypoints, scores, descriptors = sift.extract(img)\n",
        "\n",
        "      dataset.append([keypoints, scores, descriptors])\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfv75IGmzLqA"
      },
      "outputs": [],
      "source": [
        "def descriptors_toFile(folder,filename, keypoints, descriptors):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  A funtion to create dummy file into a file  in the format keypoints + descriptors (descriptors are all 0's)\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "    folders : str\n",
        "        folder where to save the file\n",
        "\n",
        "    filename : str\n",
        "        name of the file to save inside the folder\n",
        "\n",
        "    keypoints : list or array like\n",
        "        list of keypoints \n",
        "\n",
        "    descriptors : list or array like (not used)\n",
        "        list of descriptors\n",
        "  \"\"\"\n",
        "\n",
        "  with open(folder+filename,\"w\") as data_file:\n",
        "\n",
        "    #first row is the number of keypoints and the lenght of the descriptors\n",
        "    n_keypoints = str(len(keypoints))\n",
        "    len_features = str(descriptors.shape[1])\n",
        "    header = n_keypoints+\" \"+len_features+\"\\n\"\n",
        "    data_file.write(header)\n",
        "\n",
        "    #one row for each keypoint\n",
        "    for i in trange(len(keypoints)):\n",
        "      \n",
        "      # position (u,v) + scale + orientation \n",
        "      u = str(keypoints[i][0])\n",
        "      v = str(keypoints[i][1])\n",
        "      s = str(keypoints[i][2])\n",
        "      o = str(keypoints[i][3])\n",
        "      point = u + \" \" + v + \" \" + s + \" \" + o + \" \"\n",
        "    \n",
        "      #in the same row the element of the descriptor\n",
        "      \n",
        "      row = point #empty string\n",
        "      for j in range(127):\n",
        "        \n",
        "        row = row + str(0)+\" \" #element + whitespace\n",
        "\n",
        "      row = row + str(0)+\"\\n\" #instead for the last element we need to put a break line\n",
        "\n",
        "      data_file.write(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing of the datasets "
      ],
      "metadata": {
        "id": "M_EfKLcIJzce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXmyNoXN1vM-",
        "outputId": "32f9a273-ba7d-4752-da41-59e14a36b387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]<ipython-input-5-ea1ddb9f8dce>:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  img = np.array(img).astype(np.float) / 255\n",
            "100%|██████████| 30/30 [01:30<00:00,  3.00s/it]\n",
            "100%|██████████| 19/19 [00:55<00:00,  2.92s/it]\n",
            "100%|██████████| 11/11 [00:34<00:00,  3.18s/it]\n"
          ]
        }
      ],
      "source": [
        "#train set\n",
        "train_folders = [\"/content/castle-P30/images/\",\"/content/castle-P19/images/\"]\n",
        "\n",
        "train = compute_dataset(train_folders)\n",
        "\n",
        "#test set\n",
        "test_folders = [\"/content/fountain-P11/images/\"]\n",
        "\n",
        "test = compute_dataset(test_folders)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the order and the division doens't matter since these lists are used only for the training and the test and not for the matching phase."
      ],
      "metadata": {
        "id": "NRYHQ4udR8Lj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnEt2M5dcmUo",
        "outputId": "acd07b51-8da4-4b48-fdaa-7bbe5b2dfd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49/49 [00:00<00:00, 577.07it/s]\n",
            "100%|██████████| 11/11 [00:00<00:00, 564.22it/s]\n"
          ]
        }
      ],
      "source": [
        "train_descriptors = []\n",
        "\n",
        "for i in trange(len(train)):\n",
        "\n",
        "  for descriptor in train[i][2]:\n",
        "    \n",
        "    train_descriptors.append(descriptor)\n",
        "\n",
        "test_descriptors = []\n",
        "\n",
        "for i in trange(len(test)):\n",
        "\n",
        "  for descriptor in train[i][2]:\n",
        "    \n",
        "    test_descriptors.append(descriptor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder definition"
      ],
      "metadata": {
        "id": "X7amOmfjJ1ry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdVzsJh-6RNb"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(Model):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "                  Input(128),\n",
        "                  tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "                  tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                  tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "                  tf.keras.layers.Dense(8, activation=\"relu\")\n",
        "              ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "                  tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "                  tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "                  tf.keras.layers.Dense(128, activation=\"relu\")\n",
        "              ])\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xac1H9Vp9fY"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoder()\n",
        "model.compile(optimizer=\"adam\", loss = keras.metrics.mean_squared_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing"
      ],
      "metadata": {
        "id": "mxTrvuA1J-Jm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXkMjqlZ5iAL"
      },
      "outputs": [],
      "source": [
        "x_batches = np.array_split(np.array(train_descriptors), 200) #batch training \n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  # Loop over the batches of data\n",
        "  losses = []\n",
        "  for x_batch in x_batches:\n",
        "    \n",
        "    loss = model.train_on_batch(x_batch, x_batch)\n",
        "    losses.append(loss)\n",
        "    print(f'Epoch {epoch+1}, batch loss: {loss}')\n",
        "  \n",
        "  print(f'Epoch {epoch+1}, epoch loss: {np.array(losses).mean()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder network\n",
        "plot_model(model.encoder, to_file='model_plot_encoder.png', show_shapes=True, show_layer_names=False)"
      ],
      "metadata": {
        "id": "fUo764UJTOTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder network\n",
        "plot_model(model.decoder, to_file='model_plot_decoder.png', show_shapes=True, show_layer_names=False)"
      ],
      "metadata": {
        "id": "siW-J5tlBvB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMDKeAg6b-rr"
      },
      "outputs": [],
      "source": [
        "y_batches = np.array_split(np.array(test_descriptors), 200) #batch testing\n",
        "\n",
        "# Loop over the batches of data\n",
        "losses = []\n",
        "for y_batch in x_batches:\n",
        "  loss = model.test_on_batch(y_batch, y_batch)\n",
        "  losses.append(loss)\n",
        "  print(f\"Loss: {loss}\")\n",
        "\n",
        "print(f\"Mean loss: {np.array(losses).mean()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing the descriptors\n",
        "\n",
        "Notice that, in this part, we recompute the descriptors and the keypoints again because we need to mantain the separation between the datasets. This format is not suitable for the training of the network so we didn't use it before."
      ],
      "metadata": {
        "id": "2H2joKFkKBsE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVpX-h9Zzt_3"
      },
      "outputs": [],
      "source": [
        "#compute the keypoints and the descriptors for each images in the train set\n",
        "#and saving them into a dummy file\n",
        "\n",
        "train = [] #it will contains a list for each dataset used for the train \n",
        "for folder in train_folders:\n",
        "\n",
        "  tmp =[folder] #first element is the folder\n",
        "\n",
        "  files = os.listdir(folder)\n",
        "\n",
        "  #Iterate over the files(image)\n",
        "  for i in trange(len(files)):\n",
        "    \n",
        "    file = files[i]\n",
        "    \n",
        "    file_path = os.path.join(folder, file)\n",
        "\n",
        "    #checking if the path is a file or a directory\n",
        "    if os.path.isdir(file_path):\n",
        "      continue\n",
        "\n",
        "    #extracting keypounts and descriptors for the image\n",
        "    img = Image.open(file_path).convert('RGB')\n",
        "    img = ImageOps.grayscale(img)\n",
        "    img = np.array(img).astype(np.float) / 255\n",
        "    sift = pycolmap.Sift()\n",
        "    keypoints, scores, descriptors = sift.extract(img)\n",
        "\n",
        "    #name of the files, keypoints, original descriptors, compressed version, reconstructed version\n",
        "    tupla = [file,keypoints,descriptors,model.encoder.predict(descriptors),model.predict(descriptors)]\n",
        "    tmp.append(tupla)\n",
        "\n",
        "    directory = \"dummy_descriptors\"\n",
        "    path = os.path.join(folder, directory)\n",
        "    if not os.path.exists(path):\n",
        "      os.mkdir(path)\n",
        "    descriptors_toFile(path,\"/\"+file+\".txt\", keypoints, descriptors)\n",
        "  \n",
        "  train.append(tmp) #folder + a list for each image in the folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mf2eaU2UdhA"
      },
      "outputs": [],
      "source": [
        "#same comments as above applied to the test\n",
        "\n",
        "test = []\n",
        "for folder in test_folders:\n",
        "\n",
        "  tmp =[folder]\n",
        "\n",
        "  files = os.listdir(folder)\n",
        "\n",
        "  #Iterate over the files\n",
        "  for file in files:\n",
        "    print(file)\n",
        "    \n",
        "    file_path = os.path.join(folder, file)\n",
        "\n",
        "    #checking if the path is a file or a directory\n",
        "    if os.path.isdir(file_path):\n",
        "      continue\n",
        "\n",
        "    img = Image.open(file_path).convert('RGB')\n",
        "    img = ImageOps.grayscale(img)\n",
        "    img = np.array(img).astype(np.float) / 255\n",
        "    sift = pycolmap.Sift()\n",
        "\n",
        "    keypoints, scores, descriptors = sift.extract(img)\n",
        "\n",
        "    tupla = [file,keypoints,descriptors,model.encoder.predict(descriptors),model.predict(descriptors)]\n",
        "    tmp.append(tupla)\n",
        "    \n",
        "    directory = \"dummy_descriptors\"\n",
        "    path = os.path.join(folder, directory)\n",
        "    if not os.path.exists(path):\n",
        "      os.mkdir(path)\n",
        "    descriptors_toFile(path,\"/\"+file+\".txt\", keypoints, descriptors)\n",
        "  \n",
        "  test.append(tmp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the matches"
      ],
      "metadata": {
        "id": "SNbPRhR1Kdxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training set"
      ],
      "metadata": {
        "id": "Z6NSo9sjKgkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the matches between two sets of features original (train)\n",
        "matcher = cv2.BFMatcher() \n",
        "\n",
        "train_original_time = {} #dictionary used to save the execution time\n",
        "\n",
        "for i in trange(len(train)):\n",
        "\n",
        "  folder = train[i][0]\n",
        "  start = time.time() #starting time for this dataset\n",
        "  with open(folder+\"/matches_original.txt\",\"w\") as data_file:\n",
        "\n",
        "    for j in trange(1,len(train[i])):\n",
        "\n",
        "      for k in range(j+1,len(train[i])):\n",
        "\n",
        "        name1 = train[i][j][0]\n",
        "        descriptors1 =  train[i][j][2]\n",
        "\n",
        "        name2 = train[i][k][0]\n",
        "        descriptors2 =  train[i][k][2]\n",
        "\n",
        "        data_file.write(\" \\n\" + name1 + \" \" +name2 + \"\\n\")\n",
        "        \n",
        "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "        for m, n in matches:\n",
        "            if m.distance < 0.75*n.distance: #excluding false matches \n",
        "\n",
        "                data_file.write(str(m.queryIdx)+\" \"+str(m.trainIdx)+\"\\n\")\n",
        "                \n",
        "    end = time.time() #end time\n",
        "    train_original_time[folder] = end-start #data are saved in the format (key:value): \"dataset_name/images/\" : time"
      ],
      "metadata": {
        "id": "a6cfv7uZqSaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the matches between two sets of features compressed (train)\n",
        "matcher = cv2.BFMatcher() \n",
        "\n",
        "train_compressed_time = {}\n",
        "\n",
        "for i in trange(len(train)):\n",
        "\n",
        "  folder = train[i][0]\n",
        "  start = time.time()\n",
        "  with open(folder+\"/matches_compressed.txt\",\"w\") as data_file:\n",
        "\n",
        "    for j in trange(1,len(train[i])):\n",
        "\n",
        "      for k in range(j+1,len(train[i])):\n",
        "\n",
        "        name1 = train[i][j][0]\n",
        "        descriptors1 =  train[i][j][3]\n",
        "        name2 = train[i][k][0]\n",
        "        descriptors2 =  train[i][k][3]\n",
        "\n",
        "        data_file.write(\" \\n\" + name1 + \" \" +name2 + \"\\n\")\n",
        "        \n",
        "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "        for m, n in matches:\n",
        "            if m.distance < 0.75*n.distance:\n",
        "\n",
        "                data_file.write(str(m.queryIdx)+\" \"+str(m.trainIdx)+\"\\n\")\n",
        "\n",
        "    end = time.time()\n",
        "    train_compressed_time[folder] = end-start"
      ],
      "metadata": {
        "id": "FhaAHDZS2F_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the matches between two sets of features after reconstruction (train)\n",
        "matcher = cv2.BFMatcher()\n",
        "\n",
        "train_reconstructed_time = {}\n",
        "\n",
        "for i in trange(len(train)):\n",
        "\n",
        "  folder = train[i][0]\n",
        "  start = time.time()\n",
        "  with open(folder+\"/matches_reconstructed.txt\",\"w\") as data_file:\n",
        "\n",
        "    for j in trange(1,len(train[i])):\n",
        "\n",
        "      for k in range(j+1,len(train[i])):\n",
        "\n",
        "        name1 = train[i][j][0]\n",
        "        descriptors1 =  train[i][j][4]\n",
        "\n",
        "        name2 = train[i][k][0]\n",
        "        descriptors2 =  train[i][k][4]\n",
        "\n",
        "        data_file.write(\" \\n\" + name1 + \" \" +name2 + \"\\n\")\n",
        "        \n",
        "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "        for m, n in matches:\n",
        "            if m.distance < 0.75*n.distance:\n",
        "\n",
        "                data_file.write(str(m.queryIdx)+\" \"+str(m.trainIdx)+\"\\n\")\n",
        "\n",
        "    end = time.time()\n",
        "    train_reconstructed_time[folder] = end-start"
      ],
      "metadata": {
        "id": "TZa9KeWX2hj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/castle-P19_results.zip /content/castle-P19\n",
        "!zip -r /content/castle-P30_results.zip /content/castle-P30"
      ],
      "metadata": {
        "id": "Fo5MzKaP8UZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test set"
      ],
      "metadata": {
        "id": "4oEak_TvKkpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the matches between two sets of features original (test)\n",
        "matcher = cv2.BFMatcher()\n",
        " \n",
        "test_original_time = {}\n",
        "\n",
        "for i in trange(len(test)):\n",
        "\n",
        "  folder = test[i][0]\n",
        "  start = time.time()\n",
        "  with open(folder+\"/matches_original.txt\",\"w\") as data_file:\n",
        "\n",
        "    for j in trange(1,len(test[i])):\n",
        "\n",
        "      for k in range(j+1,len(test[i])):\n",
        "\n",
        "        name1 = test[i][j][0]\n",
        "        descriptors1 =  test[i][j][2]\n",
        "\n",
        "        name2 = test[i][k][0]\n",
        "        descriptors2 =  test[i][k][2]\n",
        "\n",
        "        data_file.write(\" \\n\" + name1 + \" \" +name2 + \"\\n\")\n",
        "        \n",
        "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "        for m, n in matches:\n",
        "            if m.distance < 0.75*n.distance: #excluding false matches \n",
        "\n",
        "                data_file.write(str(m.queryIdx)+\" \"+str(m.trainIdx)+\"\\n\") \n",
        "    end = time.time()\n",
        "    test_original_time[folder] = end-start   "
      ],
      "metadata": {
        "id": "PDxrRPkR-vw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the matches between two sets of features compressed (test)\n",
        "matcher = cv2.BFMatcher() \n",
        "test_compressed_time = {}\n",
        "for i in trange(len(test)):\n",
        "\n",
        "  folder = test[i][0]\n",
        "  start = time.time()\n",
        "  with open(folder+\"/matches_compressed.txt\",\"w\") as data_file:\n",
        "\n",
        "    for j in trange(1,len(test[i])):\n",
        "\n",
        "      for k in range(j+1,len(test[i])):\n",
        "\n",
        "        name1 = test[i][j][0]\n",
        "        descriptors1 =  test[i][j][3]\n",
        "        name2 = test[i][k][0]\n",
        "        descriptors2 =  test[i][k][3]\n",
        "\n",
        "        data_file.write(\" \\n\" + name1 + \" \" +name2 + \"\\n\")\n",
        "        \n",
        "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "        for m, n in matches:\n",
        "            if m.distance < 0.75*n.distance:\n",
        "\n",
        "                data_file.write(str(m.queryIdx)+\" \"+str(m.trainIdx)+\"\\n\")\n",
        "\n",
        "    end = time.time()\n",
        "    test_compressed_time[folder] = end-start "
      ],
      "metadata": {
        "id": "esuFY5w1I8QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the matches between two sets of features after reconstruction (train)\n",
        "matcher = cv2.BFMatcher() \n",
        "test_reconstructed_time = {}\n",
        "for i in trange(len(test)):\n",
        "\n",
        "  folder = test[i][0]\n",
        "  start = time.time()\n",
        "  with open(folder+\"/matches_reconstructed.txt\",\"w\") as data_file:\n",
        "\n",
        "    for j in trange(1,len(test[i])):\n",
        "\n",
        "      for k in range(j+1,len(test[i])):\n",
        "\n",
        "        name1 = test[i][j][0]\n",
        "        descriptors1 =  test[i][j][4]\n",
        "\n",
        "        name2 = test[i][k][0]\n",
        "        descriptors2 =  test[i][k][4]\n",
        "\n",
        "        data_file.write(\" \\n\" + name1 + \" \" +name2 + \"\\n\")\n",
        "        \n",
        "        matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "        for m, n in matches:\n",
        "            if m.distance < 0.75*n.distance:\n",
        "\n",
        "                data_file.write(str(m.queryIdx)+\" \"+str(m.trainIdx)+\"\\n\")\n",
        "\n",
        "    end = time.time()\n",
        "    test_reconstructed_time[folder] = end-start"
      ],
      "metadata": {
        "id": "PWp5f_H4JKAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/fountain-P11_results.zip /content/fountain-P11"
      ],
      "metadata": {
        "id": "rgE6IMqZLdy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the execution time during the matching phase"
      ],
      "metadata": {
        "id": "YEL4p-PNOJrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(BOLD+\"TRAIN SET\\n\\n\"+END)\n",
        "print(\"ORIGINAL DESCRIPTORS:\\n\")\n",
        "print(train_original_time)\n",
        "print(\"\\n\\nCOMPRESSED DESCRIPTORS:\\n\")\n",
        "print(train_compressed_time)\n",
        "print(\"\\n\\nRECONTRUCTED DESCRIPTORS:\\n\")\n",
        "print(train_reconstructed_time)\n",
        "\n",
        "print(BOLD+\"\\n\\n\\nTEST SET\\n\\n\"+END)\n",
        "print(\"ORIGINAL DESCRIPTORS:\\n\")\n",
        "print(test_original_time)\n",
        "print(\"\\n\\nCOMPRESSED DESCRIPTORS:\\n\")\n",
        "print(test_compressed_time)\n",
        "print(\"\\n\\nRECONTRUCTED DESCRIPTORS:\\n\")\n",
        "print(test_reconstructed_time)"
      ],
      "metadata": {
        "id": "cWcS4p3MONSO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}